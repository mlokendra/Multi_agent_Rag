# Contract RAG Prototype ğŸ”ğŸ“„

A lightweight, agentic retrieval-augmented QA loop for the sample contracts in `data/`, supporting local Hugging Face models (default: **Qwen/Qwen2.5-3B-Instruct**) and OpenAI chat completions.

## Quickstart ğŸš€
1) Install core dependencies (virtualenv recommended):
```bash
pip install numpy pypdf python-docx openai "torch>=2.1" "transformers>=4.39" "accelerate"
```
2) Ask a one-off question with OpenAI (set `OPENAI_API_KEY` first):
```bash
python -m contract_rag.app --llm-provider openai "What are the termination rights?"
```
3) Start an interactive chat with OpenAI:
```bash
python -m contract_rag.app --llm-provider openai
```

## Layout ğŸ—‚ï¸
- `app.py` â€“ CLI entry point and chat loop (select LLM provider at runtime)
- `config.py` â€“ defaults for chunking, retrieval, LLM provider/model, risk toggle
- `ingestion/` â€“ loaders, heading-aware chunking, simple vector index
- `retrieval/` â€“ hybrid TF-IDF/BM25-style retrieval and rerank stub
- `agents/` â€“ router, answerer, risk scorer, synthesizer
- `llm/` â€“ transformers client for local Qwen, optional Ollama stub, OpenAI client in `answerer`
- `eval/` â€“ sample dataset and runner
- `utils/` â€“ text normalization and citation helpers

### Agents ğŸ¤–
- Router: orchestrates retrieval, answering, risk scoring, and legal analysis.
- Answerer: grounded Q&A (prefers local HF model, can use OpenAI, falls back to extractive snippets).
- Legal Analyst: converts clauses into structured legal meaning and presents only populated fields.
- Risk scorer: rule-based risk flags on top retrieved evidence.
- Synthesizer: formats output as Assistant answer â†’ Legal analysis â†’ Risk flags â†’ Citations.

## Architecture ğŸ§ 

The system follows a multi-agent RAG architecture with clear separation of concerns:

User Query  
â†’ Router Agent  
â†’ Retriever (hybrid TF-IDF + vector)  
â†’ Reranker (stub / reciprocal rank fusion)  
â†’ Answerer (LLM-grounded response)  
â†’ Risk Scorer  
â†’ Synthesizer â†’ CLI Output

### Agents

- **Router** â€“ Determines intent (QA vs risk_scan) using rule-based classification.
- **Retriever** â€“ Retrieves heading-aware clause chunks from indexed contracts.
- **Reranker** â€“ Reorders candidates using reciprocal-rank fusion.
- **Answerer** â€“ Generates grounded responses using either local HF model or OpenAI.
- **Risk Scorer** â€“ Applies rule-based legal risk heuristics.
- **Synthesizer** â€“ Formats answer, citations, and risks for CLI display.

This separation improves modularity, testability, and grounded reasoning.


### Option A: Local Hugging Face model (default) ğŸ¤—

Environment (already in `.env`):
```
LLM_PROVIDER=transformers
HF_LLM_MODEL=Qwen/Qwen2.5-3B-Instruct
HF_MAX_NEW_TOKENS=200
HF_TEMPERATURE=0.1
HF_TOP_P=0.9
```

### Option B: OpenAI API ğŸ¤–
Environment:
```
LLM_PROVIDER=openai
OPENAI_API_KEY=your_key
OPENAI_CHAT_MODEL=gpt-4o-mini
```

## Running â–¶ï¸
- One-off question (provider from env):
```bash
python -m contract_rag.app "What are the termination rights?"
```
- Force a provider at runtime:
```bash
python -m contract_rag.app --llm-provider transformers "Summarize termination"
python -m contract_rag.app --llm-provider openai "Summarize termination"
python -m contract_rag.app --llm-provider none   "Summarize termination"  # extractive fallback
```
- Interactive chat:
```bash
python -m contract_rag.app
```

## Behavior ğŸ“‘
- Retrieval: heading-aware clause chunks + hybrid vector/BM25 with reciprocal-rank fusion.
- Assistant answer shown first, followed by Legal analysis (if populated), Risk flags, then Citations.
- Risk flags: run on every query by default (`RAG_ALWAYS_RISK=true`); shows severity-tagged findings under â€œRisk flagsâ€.
- Legal Analyst Agent: structures clauses into JSON (clause type, obligations, liability, governing law, survival, risk signals) and renders only populated fields. Toggle with `RAG_ENABLE_LEGAL_ANALYST=true|false`.
- Citations: show doc + section for each chunk used.

## Flow ğŸª„
1. Router detects intent (QA vs risk scan) and reuses retrieval for all agents.
2. Retrieval + rerank gather the top evidence chunks.
3. Answerer generates the grounded reply (or extractive fallback).
4. Legal Analyst (if enabled) structures obligations/liability/governing law/survival from the same evidence.
5. Risk scorer flags heuristic risks.
6. Synthesizer orders output: Assistant answer â†’ Legal analysis â†’ Risk flags â†’ Citations.

## Evaluation ğŸ§ª
```bash
python -m contract_rag.eval.run_eval
```
Reads `eval/dataset.jsonl`, runs the pipeline, and prints answers.

## Configuration Knobs ğŸ”§
- LLM provider/model: `.env` or `--llm-provider`.
- Risk scoring toggle: `RAG_ALWAYS_RISK=true|false`.
- Chunking/overlap/top_k: see `config.py`.

## Future Improvements ğŸš€

- Cross-document conflict detection agent
- Learned reranker (e.g., bge-reranker)
- LLM-based risk scoring with structured output
- Persistent vector database
- Citation confidence scoring


## Notes ğŸ“
- If the local model cannot load (e.g., missing weights/GPU), the app logs a warning and falls back to extractive snippets.
- OpenAI quota errors will trigger the fallback; check your billing/quota if that happens.
